{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0MRC0e0KhQ0S"
   },
   "source": [
    "# Hyperparamter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWd1UlMnhT2s"
   },
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YvGPUQaHhXfL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1VMqkGvhc3-"
   },
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "M52QDmyzhh9s"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample code number</th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample code number  Clump Thickness  Uniformity of Cell Size  \\\n",
       "0             1000025                5                        1   \n",
       "1             1002945                5                        4   \n",
       "2             1015425                3                        1   \n",
       "3             1016277                6                        8   \n",
       "4             1017023                4                        1   \n",
       "\n",
       "   Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size  \\\n",
       "0                         1                  1                            2   \n",
       "1                         4                  5                            7   \n",
       "2                         1                  1                            2   \n",
       "3                         8                  1                            3   \n",
       "4                         1                  3                            2   \n",
       "\n",
       "   Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
       "0            1                3                1        1      2  \n",
       "1           10                3                2        1      2  \n",
       "2            2                3                1        1      2  \n",
       "3            4                3                7        1      2  \n",
       "4            1                3                1        1      2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:/Users/user 1/Documents/Fall _ Spring 2022-2023/Course_Work/Fall 2023/Practical ML/Homeworks or Reflections/Reflection_1/Classification/Data.csv\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 1:-1].values\n",
    "y = data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvxIPVyMhmKp"
   },
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "AVzJWAXIhxoC"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kW3c7UYih0hT"
   },
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9fQlDPKCh8sc"
   },
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#sc = StandardScaler()\n",
    "#X_train = sc.fit_transform(X_train)\n",
    "#X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized SearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bb6jCOCQiAmP"
   },
   "source": [
    "#### Logistic Regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "D6bpZwUiiXic"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train Data:  98.046875\n",
      "Accuracy of Test Data:  94.73684210526315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "mod_Lr = LogisticRegression()\n",
    "mod_Lr.fit(X_train, y_train)\n",
    "y_pred = mod_Lr.predict(X_test)\n",
    "y_train_pred = mod_Lr.predict(X_train)\n",
    "\n",
    "print(\"Accuracy of Train Data: \", accuracy_score(y_train, y_train_pred)*100) \n",
    "print(\"Accuracy of Test Data: \", accuracy_score(y_test, y_pred)*100)\n",
    "\n",
    "# Note that hyperparamter did not improve the model, hence I used the default hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter Tuning of LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 97.27 %\n",
      "Best Paramters: {'solver': 'sag', 'max_iter': 50, 'C': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user 1\\anaconda3\\New_Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "parameters = [{\n",
    "                \"C\" : [0.1, 0.2,0.3,0.4, 0.5,0.6,0.7,0.8,0.9,1],\n",
    "               \"solver\": [\"lbfgs\", \"newton-cg\", \"liblinear\", \"sag\", \"saga\"],\n",
    "               \"max_iter\" : [50, 100, 200, 1000, 2500, 5000]\n",
    "       }]\n",
    "\n",
    "random_search= RandomizedSearchCV(mod_Lr, param_distributions = parameters, scoring = \"accuracy\", cv = 10, n_jobs = -1)\n",
    "\n",
    "random_search.fit(X_train,y_train)\n",
    "best_accuracy = random_search.best_score_\n",
    "best_paramters = random_search.best_params_\n",
    "\n",
    "print(\"Best Accuracy: {:.2f} %\".format((best_accuracy)*100))\n",
    "print(\"Best Paramters:\",best_paramters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103   4]\n",
      " [  5  59]]\n",
      "[[332   5]\n",
      " [  5 170]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm1 = confusion_matrix(y_train, y_train_pred)\n",
    "print(cm)\n",
    "print(cm1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train Data:  97.8515625\n",
      "Accuracy of Test Data:  95.32163742690058\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "mod_SVC = svm.SVC()\n",
    "mod_SVC = mod_SVC.fit(X_train, y_train)\n",
    "y_pred = mod_SVC.predict(X_test)\n",
    "y_train_pred = mod_SVC.predict(X_train)\n",
    "print(\"Accuracy of Train Data: \", accuracy_score(y_train, y_train_pred)*100) \n",
    "print(\"Accuracy of Test Data: \", accuracy_score(y_test, y_pred)*100) \n",
    "\n",
    "# Based on the outcome of the model, the default hyperparameters will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 97.27 %\n",
      "Best Paramters: {'kernel': 'linear', 'gamma': 0.65, 'C': 0.2}\n"
     ]
    }
   ],
   "source": [
    "parameters = [{\"C\" : [0.1, 0.2,0.3,0.4, 0.5,0.6,0.7,0.8,0.9,1],\n",
    "               \"kernel\": [\"linear\", \"rbf\", \"sigmoid\"],\n",
    "               \"gamma\": [(0.01 + x / 100) for x in range(10, 90)]\n",
    "       }]\n",
    "\n",
    "random_search9 = RandomizedSearchCV(mod_SVC, param_distributions = parameters, n_iter = 5, scoring = \"accuracy\", cv = 10, n_jobs = -1)\n",
    "\n",
    "random_search9.fit(X_train,y_train)\n",
    "best_accuracy = random_search9.best_score_\n",
    "best_paramters = random_search9.best_params_\n",
    "\n",
    "print(\"Best Accuracy: {:.2f} %\".format((best_accuracy)*100))\n",
    "print(\"Best Paramters:\",best_paramters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102   5]\n",
      " [  3  61]]\n",
      "[[329   8]\n",
      " [  3 172]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm2 = confusion_matrix(y_train, y_train_pred)\n",
    "print(cm)\n",
    "print(cm2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train Data:  97.8515625\n",
      "Accuracy of Test Data:  95.32163742690058\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "mod_DT = DecisionTreeClassifier(min_samples_split = 10, min_samples_leaf = 4, criterion = \"gini\",\n",
    "                                 random_state = 0)\n",
    "mod_DT.fit(X_train, y_train)\n",
    "y_pred1 = mod_DT.predict(X_test)\n",
    "y_train_pred1 = mod_DT.predict(X_train)\n",
    "\n",
    "print(\"Accuracy of Train Data: \", accuracy_score(y_train, y_train_pred1)*100) \n",
    "print(\"Accuracy of Test Data: \", accuracy_score(y_test, y_pred1)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparamter Tuning of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 95.90 %\n",
      "Best Paramters: {'min_samples_split': 10, 'min_samples_leaf': 4, 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "parameters = [{\"min_samples_leaf\": [1,2,3,4,5,6,7,8,9],\n",
    "              \"min_samples_split\": [int(x) for x in np.linspace(10, 200, 5)],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}]\n",
    "random_search1 = RandomizedSearchCV(mod_DT, param_distributions = parameters, scoring = \"accuracy\", \n",
    "                                   cv = 10, n_jobs = -1)\n",
    "\n",
    "random_search1.fit(X_train,y_train)\n",
    "best_accuracy = random_search1.best_score_\n",
    "best_paramters = random_search1.best_params_\n",
    "\n",
    "print(\"Best Accuracy: {:.2f} %\".format((best_accuracy)*100))\n",
    "print(\"Best Paramters:\",best_paramters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[105   2]\n",
      " [  6  58]]\n",
      "[[332   5]\n",
      " [  6 169]]\n"
     ]
    }
   ],
   "source": [
    "cm3 = confusion_matrix(y_test, y_pred1)\n",
    "cm4 = confusion_matrix(y_train, y_train_pred1)\n",
    "print(cm3)\n",
    "print(cm4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train Data:  97.65625\n",
      "Accuracy of Test Data:  95.90643274853801\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "mod_RF = RandomForestClassifier(n_estimators = 3000, criterion = \"entropy\", \n",
    "                                min_samples_split = 200, min_samples_leaf = 2, random_state = 0)\n",
    "mod_RF.fit(X_train, y_train)\n",
    "y_pred2 = mod_RF.predict(X_test)\n",
    "y_train_pred2 = mod_RF.predict(X_train)\n",
    "\n",
    "print(\"Accuracy of Train Data: \", accuracy_score(y_train, y_train_pred2)*100) \n",
    "print(\"Accuracy of Test Data: \", accuracy_score(y_test, y_pred2)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 97.46 %\n",
      "Best Paramters: {'n_estimators': 3000, 'min_samples_split': 200, 'min_samples_leaf': 2, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "parameters = [{\"min_samples_leaf\": [1,2,3,4,5,6,7,8,9],\n",
    "              \"min_samples_split\": [int(x) for x in np.linspace(10, 200, 5)],\n",
    "              \"n_estimators\": [100,150,200,300,400,500,600,700,800,900, 1000, 2000, 3000, 3300],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}]\n",
    "random_search = RandomizedSearchCV(mod_RF, param_distributions = parameters, scoring = \"accuracy\", \n",
    "                                   cv = 10, n_jobs = -1)\n",
    "\n",
    "random_search.fit(X_train,y_train)\n",
    "best_accuracy = random_search.best_score_\n",
    "best_paramters = random_search.best_params_\n",
    "\n",
    "print(\"Best Accuracy: {:.2f} %\".format((best_accuracy)*100))\n",
    "print(\"Best Paramters:\",best_paramters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102   5]\n",
      " [  2  62]]\n",
      "[[327  10]\n",
      " [  2 173]]\n"
     ]
    }
   ],
   "source": [
    "cm5 = confusion_matrix(y_test, y_pred2)\n",
    "cm6 = confusion_matrix(y_train, y_train_pred2)\n",
    "print(cm5)\n",
    "print(cm6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-optimize\n",
      "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
      "     -------------------------------------- 100.3/100.3 kB 5.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\user 1\\anaconda3\\new_anaconda\\lib\\site-packages (from scikit-optimize) (1.23.5)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\user 1\\anaconda3\\new_anaconda\\lib\\site-packages (from scikit-optimize) (1.10.0)\n",
      "Collecting pyaml>=16.9\n",
      "  Downloading pyaml-23.9.7-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\user 1\\anaconda3\\new_anaconda\\lib\\site-packages (from scikit-optimize) (1.1.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\user 1\\anaconda3\\new_anaconda\\lib\\site-packages (from scikit-optimize) (1.2.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\user 1\\anaconda3\\new_anaconda\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user 1\\anaconda3\\new_anaconda\\lib\\site-packages (from scikit-learn>=0.20.0->scikit-optimize) (2.2.0)\n",
      "Installing collected packages: pyaml, scikit-optimize\n",
      "Successfully installed pyaml-23.9.7 scikit-optimize-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train Data:  97.4609375\n",
      "Accuracy of Test Data:  93.56725146198829\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "mod_Lr_BO = LogisticRegression(C = 0.4, max_iter = 9000, solver = \"liblinear\")\n",
    "mod_Lr_BO.fit(X_train, y_train)\n",
    "y_pred = mod_Lr_BO.predict(X_test)\n",
    "y_train_pred = mod_Lr_BO.predict(X_train)\n",
    "\n",
    "print(\"Accuracy of Train Data: \", accuracy_score(y_train, y_train_pred)*100) \n",
    "print(\"Accuracy of Test Data: \", accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 97.27 %\n",
      "Best Paramters: OrderedDict([('C', 0.4), ('max_iter', 9000), ('solver', 'liblinear')])\n"
     ]
    }
   ],
   "source": [
    "search_space = [{\n",
    "                \"C\" : [0.1, 0.2,0.3,0.4, 0.5,0.6,0.7,0.8,0.9,1],\n",
    "               \"solver\": [\"lbfgs\", \"newton-cg\", \"liblinear\", \"sag\", \"saga\"],\n",
    "               \"max_iter\" : [50, 100, 200, 1000, 2500, 5000, 5500, 6000, 6500, 7000, 8000, 9000]\n",
    "       }]\n",
    "\n",
    "Bayes_search = BayesSearchCV(mod_Lr_BO, search_space, scoring = \"accuracy\", cv = 10, n_jobs = -1)\n",
    "\n",
    "Bayes_search.fit(X_train,y_train)\n",
    "best_accuracy = Bayes_search.best_score_\n",
    "best_paramters = Bayes_search.best_params_\n",
    "\n",
    "print(\"Best Accuracy: {:.2f} %\".format((best_accuracy)*100))\n",
    "print(\"Best Paramters:\",best_paramters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train Data:  99.609375\n",
      "Accuracy of Test Data:  94.73684210526315\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "mod_SVC = svm.SVC(C = 0.8, gamma = 0.18, kernel = \"rbf\")\n",
    "mod_SVC = mod_SVC.fit(X_train, y_train)\n",
    "y_pred3 = mod_SVC.predict(X_test)\n",
    "y_train_pred3 = mod_SVC.predict(X_train)\n",
    "print(\"Accuracy of Train Data: \", accuracy_score(y_train, y_train_pred3)*100) \n",
    "print(\"Accuracy of Test Data: \", accuracy_score(y_test, y_pred3)*100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 94.73 %\n",
      "Best Paramters: OrderedDict([('C', 0.8), ('gamma', 0.18000000000000002), ('kernel', 'rbf')])\n"
     ]
    }
   ],
   "source": [
    "search_space = [{\"C\" : [0.1, 0.2,0.3,0.4, 0.5,0.6,0.7,0.8,0.9,1],\n",
    "               \"kernel\": [\"linear\", \"rbf\", \"sigmoid\"],\n",
    "               \"gamma\": [(0.01 + x / 100) for x in range(10, 90)]\n",
    "       }]\n",
    "\n",
    "Bayes_search1 = BayesSearchCV(mod_SVC, search_space, n_iter = 5, scoring = \"accuracy\", cv = 10, n_jobs = -1)\n",
    "\n",
    "Bayes_search1.fit(X_train,y_train)\n",
    "best_accuracy = Bayes_search1.best_score_\n",
    "best_paramters = Bayes_search1.best_params_\n",
    "\n",
    "print(\"Best Accuracy: {:.2f} %\".format((best_accuracy)*100))\n",
    "print(\"Best Paramters:\",best_paramters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train Data:  97.8515625\n",
      "Accuracy of Test Data:  95.32163742690058\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "mod_DT = DecisionTreeClassifier(min_samples_split = 10, min_samples_leaf = 4, criterion = \"gini\",\n",
    "                                 random_state = 0)\n",
    "mod_DT.fit(X_train, y_train)\n",
    "y_pred3 = mod_DT.predict(X_test)\n",
    "y_train_pred3 = mod_DT.predict(X_train)\n",
    "\n",
    "print(\"Accuracy of Train Data: \", accuracy_score(y_train, y_train_pred3)*100) \n",
    "print(\"Accuracy of Test Data: \", accuracy_score(y_test, y_pred3)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user 1\\anaconda3\\New_Anaconda\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "C:\\Users\\user 1\\anaconda3\\New_Anaconda\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "C:\\Users\\user 1\\anaconda3\\New_Anaconda\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "C:\\Users\\user 1\\anaconda3\\New_Anaconda\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "C:\\Users\\user 1\\anaconda3\\New_Anaconda\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "C:\\Users\\user 1\\anaconda3\\New_Anaconda\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "C:\\Users\\user 1\\anaconda3\\New_Anaconda\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 96.10 %\n",
      "Best Paramters: OrderedDict([('criterion', 'gini'), ('min_samples_leaf', 4), ('min_samples_split', 10)])\n"
     ]
    }
   ],
   "source": [
    "search_space = [{\"min_samples_leaf\": [1,2,3,4,5,6,7,8,9],\n",
    "              \"min_samples_split\": [int(x) for x in np.linspace(10, 200, 5)],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}]\n",
    "Bayes_search2 = BayesSearchCV(mod_DT, search_space, scoring = \"accuracy\", cv = 10, n_jobs = -1)\n",
    "\n",
    "Bayes_search2.fit(X_train,y_train)\n",
    "best_accuracy = Bayes_search2.best_score_\n",
    "best_paramters = Bayes_search2.best_params_\n",
    "\n",
    "print(\"Best Accuracy: {:.2f} %\".format((best_accuracy)*100))\n",
    "print(\"Best Paramters:\",best_paramters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train Data:  97.4609375\n",
      "Accuracy of Test Data:  93.56725146198829\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "mod_RF = RandomForestClassifier(n_estimators = 600, criterion = \"gini\", \n",
    "                                min_samples_split = 200, min_samples_leaf = 6, random_state = 0)\n",
    "mod_RF.fit(X_train, y_train)\n",
    "y_pred4 = mod_RF.predict(X_test)\n",
    "y_train_pred4 = mod_RF.predict(X_train)\n",
    "\n",
    "print(\"Accuracy of Train Data: \", accuracy_score(y_train, y_train_pred4)*100) \n",
    "print(\"Accuracy of Test Data: \", accuracy_score(y_test, y_pred4)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user 1\\anaconda3\\New_Anaconda\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 97.65 %\n",
      "Best Paramters: OrderedDict([('criterion', 'gini'), ('min_samples_leaf', 6), ('min_samples_split', 200), ('n_estimators', 600)])\n"
     ]
    }
   ],
   "source": [
    "search_space = [{\"min_samples_leaf\": [1,2,3,4,5,6,7,8,9],\n",
    "              \"min_samples_split\": [int(x) for x in np.linspace(10, 200, 5)],\n",
    "              \"n_estimators\": [100,150,200,300,400,500,600,700,800,900, 1000, 2000, 3000, 3300],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}]\n",
    "Bayes_search3 = BayesSearchCV(mod_RF, search_space, scoring = \"accuracy\", cv = 10, n_jobs = -1)\n",
    "\n",
    "Bayes_search3.fit(X_train,y_train)\n",
    "best_accuracy = Bayes_search3.best_score_\n",
    "best_paramters = Bayes_search3.best_params_\n",
    "\n",
    "print(\"Best Accuracy: {:.2f} %\".format((best_accuracy)*100))\n",
    "print(\"Best Paramters:\",best_paramters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Discussions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "\n",
    "# Randomized SearchCV results\n",
    "\n",
    "#   ML Algorithms                      Performance Comparison\n",
    "                                   #Train            # Test\n",
    "\n",
    "# Logistic Regression               98.05            94.74    \n",
    "# Support Vector Machines           97.85            95.32\n",
    "# Decision Tree                     97.85            95.32\n",
    "# Random Forest                     97.66            95.91\n",
    "\n",
    "\n",
    "# Bayesian SearchCV results\n",
    "\n",
    "#   ML Algorithms                      Performance Comparison\n",
    "                                   #Train            # Test\n",
    "\n",
    "# Logistic Regression               97.46            93.57    \n",
    "# Support Vector Machines           99.61            94.74\n",
    "# Decision Tree                     97.85            95.85\n",
    "# Random Forest                     97.46            93.57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset used in this classification problem is also from one of the machine learning tutorial I did on Udemy. \n",
    "# Here is a link to the course \"https://www.udemy.com/course/machinelearning/\"\n",
    "# In this classification modeling, four machine learning models were implemented, the logistic regression, \n",
    "# Support Vector Machines, decision tree classifier, and the random forest classifier.\n",
    "\n",
    "# Comparing the performances of the models using both RandomizedSearchCV and BayesSearchCV, the models performed \n",
    "# almost the same. However, the Logistic regression and Random Forest models performed better using the RandomizedSearchCV\n",
    "# when compared to using the Bayesian SearchCV for HPO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
